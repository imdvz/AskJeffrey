
# AskJeffrey

A **Retrieval-Augmented Generation (RAG)** pipeline for querying the **Jeffrey Epstein Files** using AI â€” built on the **Epstein Files 20K** dataset from Hugging Face.

- Dataset: https://huggingface.co/datasets/teyler/epstein-files-20k

> ğŸ”— **Live Demo:** *(coming soon)*

---

## âš¡ Quick Demo

**Process 2M+ document lines â†’ Get accurate, source-cited answers in seconds**

### What it does
- Semantic chunking (splits by meaning, not character count)
- Hybrid retrieval: **vector similarity + keyword matching**
- Cross-encoder **re-ranking** for precision
- Grounded answers with **source citations**
- **BYOK (Bring Your Own Key):** users provide their own free OpenAI API key

---

## ğŸ¯ Key Features

- âœ… **Grounded Answers (No Hallucinations)** â€” responses are derived only from retrieved source text
- âœ… **Semantic Chunking** â€” context-aware splits where meaning shifts
- âœ… **Hybrid Search** â€” ChromaDB (vector) + BM25 (keyword)
- âœ… **Cross-Encoder Re-ranking** â€” filters results for maximum relevance
- âœ… **Source Citations** â€” every answer includes citations to the underlying chunks
- âœ… **BYOK (Bring Your Own Key)** â€” no server-side API key required
- âœ… **Fast Response** â€” ~1 second end-to-end query time (typical)
- âœ… **Interactive Chat UI** â€” Streamlit interface with conversation history

---

## ğŸ—ï¸ How It Works

### Four Stages (Simple Pipeline)

#### Stage 1 â€” Data Preparation *(offline, run once)*

```text
Raw Documents (2.5M lines)
        â†“
Clean & Reconstruct
        â†“
Semantic Chunking
        â†“
Vector Embeddings + BM25 Index
```

#### Stage 2 â€” Hybrid Retrieval

```text
User Question
        â†“
Vector Search (ChromaDB) + Keyword Search (BM25)
        â†“
Reciprocal Rank Fusion â†’ Top 15 Chunks
```

#### Stage 3 â€” Re-ranking

```text
Top 15 Chunks + Question
        â†“
Cross-Encoder Scoring
        â†“
Top 6 Most Relevant Chunks
```

#### Stage 4 â€” Grounded Answer

```text
Context + Question
        â†“
gpt-oss-120b (via OpenRouter)
        â†“
Answer with Source Citations
```

---

## ğŸ§  Why Hybrid Search + Re-ranking?

**Typical RAG:** vector similarity only
â†’ often misses **exact names, dates, identifiers**, and keyword-heavy queries.

**AskJeffrey:** vector + BM25 + cross-encoder
â†’ captures **semantic meaning + exact matches**, then **precision-filters** results before generation.

---

## âœ¨ What Makes This Different?

| Feature    | Typical RAG Projects  | AskJeffrey                            |
| ---------- | --------------------- | ------------------------------------- |
| Chunking   | Fixed-size splits     | **Semantic chunking** (meaning-based) |
| Search     | Vector only           | **Hybrid** (vector + BM25 keyword)    |
| Ranking    | No re-ranking         | **Cross-encoder re-ranking**          |
| Embeddings | MiniLM (384d)         | **BGE-base-en-v1.5** (768d)           |
| API Key    | Hardcoded/server-side | **BYOK** (user provides their own)    |
| Citations  | Often missing         | **Always included**                   |

---

## ğŸ“¦ Installation

### Requirements

* Python **3.11+**
* A free **OpenAI API key**: [https://openrouter.ai/](https://openrouter.ai/)

### Setup (5 minutes)

#### 1) Clone the repository

```bash
git clone https://github.com/imdvz/AskJeffrey.git
cd AskJeffrey
```

#### 2) Create and activate a virtual environment

```bash
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
```

#### 3) Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Getting Started

### Run the Data Pipeline *(first time only)*

```bash
# Step 1: Download raw data
python ingest/download_dataset.py

# Step 2: Clean and reconstruct documents
python ingest/clean_dataset.py

# Step 3: Semantic chunking
python ingest/chunk_dataset.py

# Step 4: Generate embeddings + BM25 index
python ingest/embed_chunks.py
```

### Launch the App

```bash
streamlit run app.py
```

Open: `http://localhost:8501`

Paste your **OpenAI API key** in the sidebar and start asking questions.

---

## ğŸ“š Project Structure

```text
AskJeffrey/
â”œâ”€â”€ ingest/                         # Data processing pipeline
â”‚   â”œâ”€â”€ download_dataset.py          # Download from Hugging Face
â”‚   â”œâ”€â”€ clean_dataset.py             # Clean & reconstruct docs
â”‚   â”œâ”€â”€ chunk_dataset.py             # Semantic chunking
â”‚   â””â”€â”€ embed_chunks.py              # Embed & build BM25 index
â”‚
â”œâ”€â”€ retrieval/                       # Retrieval logic
â”‚   â”œâ”€â”€ hybrid_retriever.py          # Vector + BM25 hybrid search
â”‚   â””â”€â”€ reranker.py                  # Cross-encoder re-ranking
â”‚
â”œâ”€â”€ core/                            # Core RAG chain
â”‚   â””â”€â”€ rag_chain.py                 # Orchestrates retrieval â†’ LLM
â”‚
â”œâ”€â”€ api/                             # FastAPI backend (optional)
â”‚   â”œâ”€â”€ main.py                      # API routes
â”‚   â”œâ”€â”€ models.py                    # Pydantic models
â”‚   â””â”€â”€ prompts.py                   # Prompt templates
â”‚
â”œâ”€â”€ app.py                           # Streamlit frontend
â”œâ”€â”€ config.py                        # Central configuration
â”œâ”€â”€ requirements.txt                 # Python dependencies
â””â”€â”€ .env.example                     # Environment template
```

---

## ğŸ” Bring Your Own Key (BYOK)

This app does **not** use a server-side API key. Every user provides their own free OpenAI API key:

* ğŸ”’ Key is **not stored** (browser session only)
* ğŸš« Key is **not logged**
* ğŸ—‘ï¸ Closing the tab clears it

---

## ğŸ“œ License

Licensed under the **MIT License** â€” see `LICENSE`.

---

## ğŸ™ Acknowledgments

* **Dataset:** Teyler / Epstein Files 20K (Hugging Face)
  [https://huggingface.co/datasets/teyler/epstein-files-20k](https://huggingface.co/datasets/teyler/epstein-files-20k)
* **Embeddings:** Sentence Transformers â€” [https://www.sbert.net/](https://www.sbert.net/)
* **Vector DB:** ChromaDB â€” [https://www.trychroma.com/](https://www.trychroma.com/)
* **Keyword Search:** rank-bm25 â€” [https://github.com/dorianbrown/rank_bm25](https://github.com/dorianbrown/rank_bm25)
* **Re-ranking:** Cross-Encoders â€” [https://www.sbert.net/docs/cross_encoder/usage/usage.html](https://www.sbert.net/docs/cross_encoder/usage/usage.html)
* **LLM Inference:** OpenAI (gpt-oss-120b) â€” [https://openrouter.ai/](https://openrouter.ai/)
* **Framework:** LangChain â€” [https://langchain.com/](https://langchain.com/)
* **UI:** Streamlit â€” [https://streamlit.io/](https://streamlit.io/)

---

## ğŸ“ Support

* ğŸ“ Issues: [https://github.com/imdvz/AskJeffrey/issues](https://github.com/imdvz/AskJeffrey/issues)
* ğŸ’¬ Discussions: [https://github.com/imdvz/AskJeffrey/discussions](https://github.com/imdvz/AskJeffrey/discussions)

---

## âš ï¸ Disclaimer

Built for **research, transparency, and educational purposes**.
All data is sourced from public records. Users are responsible for complying with applicable laws and ethical guidelines.
