Got it â€” here's the entire README as one single unbroken code block:

```markdown
# ğŸ•µï¸ AskJeffrey

A RAG pipeline implementation for querying the Jeffrey Epstein Files using AI â€” built on the [Epstein Files 20K](https://huggingface.co/datasets/teyler/epstein-files-20k) dataset from Hugging Face.

> ğŸ”— **[Try the Live Demo â†’](#)** *(coming soon)*

---

## âš¡ Quick Demo

Process 2M+ document lines â†’ Get accurate, source-cited answers in seconds

**What it does:**
- Semantically chunks documents based on meaning, not character count
- Searches using both vector similarity AND keyword matching (hybrid search)
- Re-ranks results with a cross-encoder for maximum precision
- Generates grounded answers with source citations
- Users bring their own free API key â€” no server costs

---

## ğŸ¯ Key Features

âœ… **No Hallucinations** - Answers grounded solely in source documents
âœ… **Semantic Chunking** - Context-aware splits where meaning shifts
âœ… **Hybrid Search** - Vector (ChromaDB) + Keyword (BM25) retrieval
âœ… **Cross-Encoder Re-ranking** - Precision filtering of retrieved chunks
âœ… **Source Citations** - Every answer cites its source documents
âœ… **BYOK (Bring Your Own Key)** - Users provide their own free Groq API key
âœ… **Fast Processing** - ~1 second end-to-end query response
âœ… **Interactive Chat UI** - Streamlit web interface with conversation history

---

## ğŸ—ï¸ How It Works

### Four Simple Stages

**Stage 1: Data Preparation** *(offline, run once)*

```

Raw Documents (2.5M lines)

â†“

Clean & Reconstruct

â†“

Semantic Chunking

â†“

Vector Embeddings + BM25 Index

```

**Stage 2: Hybrid Retrieval**

```

User Question

â†“

Vector Search (ChromaDB) + Keyword Search (BM25)

â†“

Reciprocal Rank Fusion â†’ Top 15 Chunks

```

**Stage 3: Re-ranking**

```

Top 15 Chunks + Question

â†“

Cross-Encoder Scoring

â†“

Top 6 Most Relevant Chunks

```

**Stage 4: Grounded Answer**

```

Context + Question

â†“

LLaMA 3.3 70B (via Groq)

â†“

Answer with Source Citations

```

### Why Hybrid Search + Re-ranking?

**Typical Approach:** Pure vector similarity
â†’ Misses exact names, dates, and keywords

**AskJeffrey's Approach:** Vector + BM25 + Cross-Encoder
â†’ Catches both semantic meaning AND exact matches, then precision-filters the results

---

## âœ¨ What Makes This Different?

| Feature | Typical RAG Projects | AskJeffrey |
|---|---|---|
| Chunking | Fixed character splits | **Semantic chunking** (meaning-based) |
| Search | Vector similarity only | **Hybrid** (vector + BM25 keyword) |
| Ranking | No re-ranking | **Cross-encoder re-ranking** |
| Embeddings | MiniLM (384d) | **BGE-base-en-v1.5** (768d) |
| API Key | Hardcoded / server-side | **BYOK** (user provides their own) |
| Citations | None | **Source documents cited** in answers |

---

## ğŸ“¦ Installation

### Requirements
- Python 3.11+
- A free Groq API key ([get one here](https://console.groq.com))

### Setup (5 minutes)

**1. Clone repository**

```

git clone https://github.com/imdvz/AskJeffrey.git

cd AskJeffrey

```

**2. Create virtual environment**

```

python -m venv venv

source venv/bin/activate  # Windows: venvScriptsactivate

```

**3. Install dependencies**

```

pip install -r requirements.txt

```

---

## ğŸš€ Getting Started

### Run the Data Pipeline (first time only)

```

# Step 1: Download raw data

python ingest/download_[dataset.py](http://dataset.py)

# Step 2: Clean and reconstruct documents

python ingest/clean_[dataset.py](http://dataset.py)

# Step 3: Semantic chunking

python ingest/chunk_[dataset.py](http://dataset.py)

# Step 4: Generate embeddings + BM25 index

python ingest/embed_[chunks.py](http://chunks.py)

```

### Launch the App

```

streamlit run [app.py](http://app.py)

```

UI opens at: `http://localhost:8501`

**That's it!** Paste your Groq API key in the sidebar and start asking questions.

---

## ğŸ“š Project Structure

```

AskJeffrey/

â”œâ”€â”€ ingest/                        # Data processing pipeline

â”‚   â”œâ”€â”€ download_[dataset.py](http://dataset.py)        # Download from Hugging Face

â”‚   â”œâ”€â”€ clean_[dataset.py](http://dataset.py)           # Clean & reconstruct docs

â”‚   â”œâ”€â”€ chunk_[dataset.py](http://dataset.py)           # Semantic chunking

â”‚   â””â”€â”€ embed_[chunks.py](http://chunks.py)            # Embed & build BM25 index

â”œâ”€â”€ retrieval/                     # Retrieval logic

â”‚   â”œâ”€â”€ hybrid_[retriever.py](http://retriever.py)        # Vector + BM25 hybrid search

â”‚   â””â”€â”€ [reranker.py](http://reranker.py)                # Cross-encoder re-ranking

â”œâ”€â”€ core/                          # Core RAG chain

â”‚   â””â”€â”€ rag_[chain.py](http://chain.py)               # Orchestrates retrieval â†’ LLM

â”œâ”€â”€ api/                           # FastAPI backend (optional)

â”‚   â”œâ”€â”€ [main.py](http://main.py)                    # API routes

â”‚   â”œâ”€â”€ [models.py](http://models.py)                  # Pydantic models

â”‚   â””â”€â”€ [prompts.py](http://prompts.py)                 # Prompt templates

â”œâ”€â”€ [app.py](http://app.py)                         # Streamlit frontend

â”œâ”€â”€ [config.py](http://config.py)                      # Central configuration

â”œâ”€â”€ requirements.txt               # Python dependencies

â””â”€â”€ .env.example                   # Environment template

```

---

## ğŸ” Bring Your Own Key (BYOK)

This app does **not** use a server-side API key. Every user provides their own free Groq API key:

- ğŸ”’ Your key is **never stored** â€” it lives only in your browser session
- ğŸš« Your key is **never logged** â€” it's sent directly to Groq's API and nowhere else
- ğŸ—‘ï¸ When you close the tab, your key is **gone**

---

## ğŸ“œ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- **Dataset:** [Teyler/Epstein Files 20K](https://huggingface.co/datasets/teyler/epstein-files-20k) on Hugging Face
- **Embeddings:** [Sentence Transformers](https://www.sbert.net/)
- **Vector DB:** [ChromaDB](https://www.trychroma.com/)
- **Keyword Search:** [rank-bm25](https://github.com/dorianbrown/rank_bm25)
- **Re-ranker:** [Cross-Encoders](https://www.sbert.net/docs/cross_encoder/usage/usage.html)
- **LLM Inference:** [Groq](https://groq.com/)
- **Framework:** [LangChain](https://langchain.com/)
- **UI:** [Streamlit](https://streamlit.io/)

---

## ğŸ“ Support

**Get Help:**
- ğŸ“ [Open an Issue](https://github.com/imdvz/AskJeffrey/issues)
- ğŸ’¬ [Start a Discussion](https://github.com/imdvz/AskJeffrey/discussions)

---

## âš ï¸ Disclaimer

This project is built for **research, transparency, and educational purposes**. All data is sourced from public records. Users are responsible for complying with applicable laws and ethical guidelines when using this system.

---
```
